{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "477e8458-5ffa-4de2-855e-e2d13eec9de3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import logging\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import logging\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e28ae35-e12f-4b01-bcfc-20d7db54d9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "\n",
    "class MultiThreading(object):\n",
    "\n",
    "    def __init__(self, scrapers):\n",
    "        self.scrapers = scrapers\n",
    "\n",
    "    def run(self):\n",
    "        threads = []\n",
    "\n",
    "        for i in range(len(self.scrapers)):\n",
    "            t = threading.Thread(target=self.scrapers[i].start)\n",
    "            t.start()\n",
    "            threads.append(t)\n",
    "\n",
    "        for thread in threads:\n",
    "            thread.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c0429a5-f152-4f8e-a587-cd6cd1b2e862",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scraper(object):\n",
    "    \"\"\"\n",
    "    Pull player info down from web\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize array to store player\n",
    "    players_scraped = []\n",
    "\n",
    "    # Instantiate scraper\n",
    "    def __init__(self, urls):\n",
    "        self.urls = urls\n",
    "        self.logger = logging.getLogger(\"sLogger\")\n",
    "\n",
    "    # request to get the url\n",
    "    def get_page(self, url):\n",
    "        response = requests.get(url)\n",
    "        if response.status_code:\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            return soup.find(\"tbody\", {\"class\": \"list\"})\n",
    "        else:\n",
    "            self.logger.error(\"Error\" + response.status_code)\n",
    "            return None\n",
    "\n",
    "    # helper method to get players\n",
    "    def get_players(self,trs):\n",
    "        return [extract_info(tr) for tr in trs]\n",
    "    \n",
    "    # helper method to get stats\n",
    "    def get_stats(self,trs):\n",
    "        return [extract_stats(tr) for tr in trs]\n",
    "\n",
    "    # method to extract and copy player info from web\n",
    "    def scrap(self, urls):\n",
    "        for url in urls:\n",
    "            tbody = self.get_page(url)\n",
    "            if tbody is None:\n",
    "                continue\n",
    "            trs = tbody.findAll(\"tr\")\n",
    "            Scraper.players_scraped.append(self.get_players(trs))\n",
    "            self.logger.info(\"Page{} scraped\".format(len(Scraper.players_scraped)))\n",
    "    # method to start the scraper\n",
    "    def start(self):\n",
    "        self.scrap(self.urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3db4af9a-67a7-4a54-ba04-06ae0962bf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"ae\": \"0\", \"oa\": \"1\", \"pt\": \"2\", \"vl\": \"3\", \"wg\": \"4\", \"bp\": \"5\"}\n",
    "query = \"&\".join([f\"showCol%5B{y}%5D={x}\" for x, y in params.items()])\n",
    "url = f\"https://sofifa.com/players?{query}&offset=\"\n",
    "urls = [url + str(offset) for offset in range(0, 120, 60)]\n",
    "# Parameters\n",
    "number_of_scraper = 31\n",
    "pages = 10\n",
    "\n",
    "scrapers = [Scraper(urls[pages * i:min(pages * (i + 1), len(urls))]) \n",
    "            for i in range(number_of_scraper)]\n",
    "multi_threading = MultiThreading(scrapers)\n",
    "\n",
    "#     multi_threading.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3bb42f0-1757-484c-8990-16b945fe678b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-36:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\chunq\\miniconda3\\lib\\threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\chunq\\miniconda3\\lib\\threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\chunq\\AppData\\Local\\Temp\\ipykernel_26192\\2101840584.py\", line 43, in start\n",
      "  File \"C:\\Users\\chunq\\AppData\\Local\\Temp\\ipykernel_26192\\2101840584.py\", line 39, in scrap\n",
      "  File \"C:\\Users\\chunq\\AppData\\Local\\Temp\\ipykernel_26192\\2101840584.py\", line 26, in get_players\n",
      "  File \"C:\\Users\\chunq\\AppData\\Local\\Temp\\ipykernel_26192\\2101840584.py\", line 26, in <listcomp>\n",
      "  File \"C:\\Users\\chunq\\AppData\\Local\\Temp\\ipykernel_26192\\4213655379.py\", line 16, in extract_info\n",
      "  File \"C:\\Users\\chunq\\AppData\\Local\\Temp\\ipykernel_26192\\4213655379.py\", line 27, in extract_stats\n",
      "  File \"C:\\Users\\chunq\\AppData\\Local\\Temp\\ipykernel_26192\\4213655379.py\", line 34, in extract_deep\n",
      "  File \"C:\\Users\\chunq\\AppData\\Local\\Temp\\ipykernel_26192\\156001694.py\", line 39, in extract_mentality\n",
      "IndexError: list index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi threading time taken:  0.6133286952972412\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "multi_threading.run()\n",
    "def flatten(d):\n",
    "    out = {}\n",
    "    for key, val in d.items():\n",
    "        if isinstance(val, dict):\n",
    "            val = [val]\n",
    "        if isinstance(val, list):\n",
    "            for subdict in val:\n",
    "                deeper = flatten(subdict).items()\n",
    "                out.update({key2: val2 for key2, val2 in deeper})\n",
    "        else:\n",
    "            out[key] = val\n",
    "    return out\n",
    "players = list(map(flatten, (chain.from_iterable(Scraper.players_scraped))))\n",
    "\n",
    "df_multi_thread = pd.DataFrame(players)\n",
    "df_multi_thread.drop_duplicates(ignore_index = True)\n",
    "print(\"Multi threading time taken: \", time.time() - t1)\n",
    "df_multi_thread.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4066dab5-1ff7-461f-b318-9d6a616911b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/raw/full_stats.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "866813fb-fa0d-4f70-82cd-eedaf16cad6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_array = Scraper.players_scraped\n",
    "players = list(chain.from_iterable(test_array))\n",
    "te = list(map(flatten, players))\n",
    "df = pd.DataFrame(te)\n",
    "df.drop_duplicates(ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8d908a63-a4b5-4bcf-8188-f6f217ba9689",
   "metadata": {},
   "outputs": [],
   "source": [
    "pls = []\n",
    "params = {\"ae\": \"0\", \"oa\": \"1\", \"pt\": \"2\", \"vl\": \"3\", \"wg\": \"4\", \"bp\": \"5\"}\n",
    "query = \"&\".join([f\"showCol%5B{y}%5D={x}\" for x, y in params.items()])\n",
    "url = f\"https://sofifa.com/players?{query}&offset=\"\n",
    "urls = [url + str(offset) for offset in range(0, 120, 60)]\n",
    "for url in urls:\n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.content, \"html.parser\")\n",
    "    tbody = soup.find(\"tbody\", {\"class\": \"list\"})\n",
    "    trs = tbody.findAll(\"tr\")\n",
    "    pls.append([extract_info(tr) for tr in trs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "743627cb-1073-4bdf-95d4-cd25e3d67456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'44'"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://sofifa.com/player/27488/jan-vennegoor-of-hess/120002/\"\n",
    "new_res = requests.get(url)\n",
    "soup = BeautifulSoup(new_res.content, \"html.parser\")\n",
    "tbody = soup.find_all(\"div\", {\"class\": \"center\"})[5]\n",
    "stats_block = tbody.findAll(\"div\", {\"class\": \"block-quarter\"})\n",
    "\n",
    "att = stats_block[0].find(\"ul\")\n",
    "att.select(\"li\")[0].find(\"span\").text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "4515fed0-a7ce-4cec-8c56-27eb8134562f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['44 Crossing\\n',\n",
       " '74 Finishing\\n',\n",
       " '83 Heading Accuracy\\n',\n",
       " '63 Short Passing\\n',\n",
       " '67 Volleys\\n']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "91ddebcd-4d20-4fdf-af85-59f39a3a895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper method for extracting data of the player\n",
    "\n",
    "def extract_info(tr):\n",
    "    base = \"https://sofifa.com/\"\n",
    "    link = base + tr.select('td.col-name')[0].find(\"a\").get(\"href\")\n",
    "    print(link)\n",
    "    return {\n",
    "        \"link\" : link,\n",
    "        \"name\": tr.select('td.col-name')[0].find(\"a\").get(\"aria-label\"),\n",
    "        \"country\": tr.select('td.col-name')[0].find(\"img\").get(\"title\"),\n",
    "        \"age\": tr.select('td.col.col-ae')[0].text.strip(),\n",
    "        \"overall\": tr.select('td.col.col-oa')[0].text.strip(),\n",
    "        \"potential\": tr.select('td.col.col-pt')[0].text.strip(),\n",
    "        \"club\": tr.select(\"td.col-name\")[1].find(\"a\").text,\n",
    "        \"best_position\": tr.select('td.col-name')[0].find(\"span\").text,\n",
    "        \"value\": tr.select('td.col.col-vl')[0].text.strip(),\n",
    "        \"wage\": tr.select('td.col.col-wg')[0].text.strip()\n",
    "        #\"stats\": extract_stats(link)\n",
    "    }\n",
    "\n",
    "\n",
    "# helper method for extracting stats of single player\n",
    "\n",
    "def extract_stats(link):\n",
    "    new_res = requests.get(link)\n",
    "    soup = BeautifulSoup(new_res.content, \"html.parser\")\n",
    "    tbody = soup.find_all(\"div\", {\"class\": \"center\"})[5]\n",
    "    stats_block = tbody.findAll(\"div\", {\"class\": \"block-quarter\"})\n",
    "    return extract_deep(stats_block)\n",
    "\n",
    "\n",
    "def extract_deep(tr):\n",
    "    return {\"Att\": extract_att(tr[0]),\n",
    "            \"Skill\": extract_skill(tr[1]),\n",
    "            \"Move\": extract_move(tr[2]),\n",
    "            \"Power\": extract_pow(tr[3]),\n",
    "            \"Mentality\": extract_mentality(tr[4]),\n",
    "            \"Defending\": extract_def(tr[5]),\n",
    "            \"Goalkeep\": extract_goalkeep(tr[6])\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "54f10a72-9d55-4a3e-b4f4-c96b580f1142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_att(att):\n",
    "    return {\"crossing\": att.findAll(\"li\")[0].find(\"span\").text.strip(),\n",
    "            \"Finishing\": att.findAll(\"li\")[1].find(\"span\").text.strip(),\n",
    "            \"Heading Accuracy\":  att.findAll(\"li\")[2].find(\"span\").text.strip(),\n",
    "            \"Short passing\": att.findAll(\"li\")[3].find(\"span\").text.strip(),\n",
    "            \"Volleys\": att.findAll(\"li\")[4].find(\"span\").text.strip()\n",
    "            }\n",
    "\n",
    "\n",
    "def extract_skill(ski):\n",
    "    return {\"Dribbling\": ski.findAll(\"li\")[0].find(\"span\").text.strip(),\n",
    "            \"Curve\": ski.findAll(\"li\")[1].find(\"span\").text.strip(),\n",
    "            \"Fk Accuracy\": ski.findAll(\"li\")[2].find(\"span\").text.strip(),\n",
    "            \"Long Passing\": ski.findAll(\"li\")[3].find(\"span\").text.strip(),\n",
    "            \"Ball Control\": ski.findAll(\"li\")[4].find(\"span\").text.strip()\n",
    "            }\n",
    "\n",
    "\n",
    "def extract_move(mov):\n",
    "    return {\"Acceleration\": mov.findAll(\"li\")[0].find(\"span\").text.strip(),\n",
    "            \"Sprint Speed\": mov.findAll(\"li\")[1].find(\"span\").text.strip(),\n",
    "            \"Agility\": mov.findAll(\"li\")[2].find(\"span\").text.strip(),\n",
    "            \"Reactions\": mov.findAll(\"li\")[3].find(\"span\").text.strip(),\n",
    "            \"Balance\": mov.findAll(\"li\")[4].find(\"span\").text.strip()\n",
    "            }\n",
    "\n",
    "\n",
    "def extract_pow(pow):\n",
    "    return {\"Shot Power\": pow.findAll(\"li\")[0].find(\"span\").text.strip(),\n",
    "            \"Jumping\": pow.findAll(\"li\")[1].find(\"span\").text.strip(),\n",
    "            \"Stamina\": pow.findAll(\"li\")[2].find(\"span\").text.strip(),\n",
    "            \"Strength\": pow.findAll(\"li\")[3].find(\"span\").text.strip(),\n",
    "            \"Long Shots\": pow.findAll(\"li\")[4].find(\"span\").text.strip()\n",
    "            }\n",
    "\n",
    "\n",
    "def extract_mentality(men):\n",
    "    return {\"Aggression\": men.findAll(\"li\")[0].find(\"span\").text.strip(),\n",
    "            \"Interceptions\": men.findAll(\"li\")[1].find(\"span\").text.strip(),\n",
    "            \"Positioning\": men.findAll(\"li\")[2].find(\"span\").text.strip(),\n",
    "            \"Vision\": men.findAll(\"li\")[3].find(\"span\").text.strip(),\n",
    "            \"Penalties\": men.findAll(\"li\")[4].find(\"span\").text.strip(),\n",
    "            \"Composure\": men.findAll(\"li\")[5].find(\"span\").text.strip()\n",
    "            }\n",
    "\n",
    "\n",
    "def extract_def(defe):\n",
    "    return {\"Defensive Awareness\": defe.findAll(\"li\")[0].find(\"span\").text.strip(),\n",
    "            \"Standing Tackle\": defe.findAll(\"li\")[1].find(\"span\").text.strip(),\n",
    "            \"Sliding Tackle\": defe.findAll(\"li\")[2].find(\"span\").text.strip()\n",
    "            }\n",
    "\n",
    "\n",
    "def extract_goalkeep(gk):\n",
    "    return {\"Diving\": gk.findAll(\"li\")[0].find(\"span\").text.strip(),\n",
    "            \"Handling\": gk.findAll(\"li\")[1].find(\"span\").text.strip(),\n",
    "            \"Kicking\": gk.findAll(\"li\")[2].find(\"span\").text.strip(),\n",
    "            \"Positioning\": gk.findAll(\"li\")[3].find(\"span\").text.strip(),\n",
    "            \"Reflexes\": gk.findAll(\"li\")[4].find(\"span\").text.strip()\n",
    "            }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bc45ca-7c33-4736-ae67-dabf774bd1ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prototype\n",
    "\n",
    "- Refactor the Scraper class, so that it has different branch of statements to handle either scrap surface only or scrap deep only"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
